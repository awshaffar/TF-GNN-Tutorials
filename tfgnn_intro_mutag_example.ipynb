{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScitaPqhKtuW"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow GNN Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMqWDc_m6rUC"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSJANANlu8hp"
      },
      "source": [
        "# Molecular Graph Classification with TF-GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzRjo2fLu9A1"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/gnn/blob/master/examples/notebooks/intro_mutag_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/gnn/blob/main/examples/notebooks/intro_mutag_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiVSmMbrtCl0"
      },
      "source": [
        "We will demonstrate how to do graph classification with TF-GNN.\n",
        "\n",
        "For this example, we will do molecular property prediction, where each molecule is represented as a graph. Nodes correspond to atoms, and edges represent the bonds between them. This is one of the application areas where GNNs are now the method of choice.\n",
        "\n",
        "We will use the MUTAG dataset, a common dataset from the [TUDatasets](https://chrsmrrs.github.io/datasets/) collection.\n",
        "\n",
        "There are 188 graphs in this dataset, labeled with one of two classes, representing \"their mutagenic effect on a specific gram negative bacterium\". Node features represent the 1-hot encoding of the atom type (0=C, 1=N, 2=O, 3=F, 4=I, 5=Cl, 6=Br). Edge features  represent the bond type.\n",
        "\n",
        "Please note that this is an introductory example on homogeneous graphs (one node type, and one edge type). TF-GNN is designed to support heterogeneous graphs as well (multiple node types, and/or multiple edge types)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u55FfUXBs_0u"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS8ot98DEgzJ"
      },
      "source": [
        "Before Python can `import tensorflow_gnn`, the PIP package [`tensorflow-gnn`](https://pypi.org/project/tensorflow-gnn/) needs to be downloaded and installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jShUzy75-L9y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-gnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WlEpI7zrSHhb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-01 13:12:05.492169: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-01 13:12:05.514775: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-01 13:12:05.514804: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-01 13:12:05.515471: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-01 13:12:05.520324: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-01 13:12:05.520766: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-01 13:12:06.138859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running TF-GNN 1.0.2 with TensorFlow 2.15.1.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_gnn as tfgnn\n",
        "\n",
        "print(f'Running TF-GNN {tfgnn.__version__} with TensorFlow {tf.__version__}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmY2hw5Iqty2"
      },
      "source": [
        "### Download the MUTAG dataset\n",
        "We have created a version of the MUTAG Dataset in TF-GNN's file format to use as an example in this colab.\n",
        "\n",
        "Citation: [Morris, Christopher, et al. Tudataset: A collection of benchmark datasets for learning with graphs. arXiv preprint arXiv:2007.08663. 2020.](https://chrsmrrs.github.io/datasets/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nLAzXPvLpQgw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-01 13:12:08--  https://storage.googleapis.com/download.tensorflow.org/data/mutag.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.76.155, 142.250.206.219, 172.217.161.251, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.76.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18090 (18K) [application/zip]\n",
            "Saving to: ‘mutag.zip’\n",
            "\n",
            "mutag.zip           100%[===================>]  17.67K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-01 13:12:09 (505 KB/s) - ‘mutag.zip’ saved [18090/18090]\n",
            "\n",
            "Archive:  mutag.zip\n",
            "   creating: mutag/\n",
            "  inflating: __MACOSX/._mutag        \n",
            "  inflating: mutag/train.tfrecords   \n",
            "  inflating: mutag/val.tfrecords     \n"
          ]
        }
      ],
      "source": [
        "# Download and unzip dataset.\n",
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/mutag.zip\n",
        "!unzip mutag.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H4VykVm_qty3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 awachid awachid 217762 Dec 18  2021 /home/awachid/codes/gnn/mutag/train.tfrecords\n",
            "-rw-r--r-- 1 awachid awachid  54386 Dec 18  2021 /home/awachid/codes/gnn/mutag/val.tfrecords\n"
          ]
        }
      ],
      "source": [
        "train_path = os.path.join(os.getcwd(), 'mutag', 'train.tfrecords')\n",
        "val_path = os.path.join(os.getcwd(), 'mutag', 'val.tfrecords')\n",
        "!ls -l {train_path} {val_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qwjaaCAXRYtj"
      },
      "outputs": [],
      "source": [
        "graph_tensor_spec = tfgnn.GraphTensorSpec.from_piece_specs(\n",
        "    context_spec=tfgnn.ContextSpec.from_field_specs(features_spec={\n",
        "                  'label': tf.TensorSpec(shape=(1,), dtype=tf.int32)\n",
        "    }),\n",
        "    node_sets_spec={\n",
        "        'atoms':\n",
        "            tfgnn.NodeSetSpec.from_field_specs(\n",
        "                features_spec={\n",
        "                    tfgnn.HIDDEN_STATE:\n",
        "                        tf.TensorSpec((None, 7), tf.float32)\n",
        "                },\n",
        "                sizes_spec=tf.TensorSpec((1,), tf.int32))\n",
        "    },\n",
        "    edge_sets_spec={\n",
        "        'bonds':\n",
        "            tfgnn.EdgeSetSpec.from_field_specs(\n",
        "                features_spec={\n",
        "                    tfgnn.HIDDEN_STATE:\n",
        "                        tf.TensorSpec((None, 4), tf.float32)\n",
        "                },\n",
        "                sizes_spec=tf.TensorSpec((1,), tf.int32),\n",
        "                adjacency_spec=tfgnn.AdjacencySpec.from_incident_node_sets(\n",
        "                    'atoms', 'atoms'))\n",
        "    })\n",
        "\n",
        "\n",
        "def decode_fn(record_bytes):\n",
        "  graph = tfgnn.parse_single_example(\n",
        "      graph_tensor_spec, record_bytes, validate=True)\n",
        "\n",
        "  # extract label from context and remove from input graph\n",
        "  context_features = graph.context.get_features_dict()\n",
        "  label = context_features.pop('label')\n",
        "  new_graph = graph.replace_features(context=context_features)\n",
        "\n",
        "  return new_graph, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9VMiHec0V4BP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-01 13:12:19.176259: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-04-01 13:12:19.176532: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.data.TFRecordDataset([train_path]).map(decode_fn)\n",
        "val_ds = tf.data.TFRecordDataset([val_path]).map(decode_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n3NZ-Tk-Woh"
      },
      "source": [
        "### Look at one example from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J0BjC-y6-asJ"
      },
      "outputs": [],
      "source": [
        "g, y = train_ds.take(1).get_single_element()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls-prW6QC27_"
      },
      "source": [
        "#### Node features\n",
        "\n",
        "Node features represent the 1-hot encoding of the atom type (0=C, 1=N, 2=O, 3=F,\n",
        "4=I, 5=Cl, 6=Br)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s8JabcxqC0ja"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]], shape=(14, 7), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(g.node_sets['atoms'].features[tfgnn.HIDDEN_STATE])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QCQkE8RDYOX"
      },
      "source": [
        "#### Bond Edges\n",
        "\n",
        "In this example, we consider the bonds between atoms undirected edges. To encode\n",
        "them in the GraphsTuple, we store the undirected edges as pairs of directed\n",
        "edges in both directions.\n",
        "\n",
        "`adjacency.source` contains the source node indices, and `adjacency.target` contains the corresponding target node indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxUPaUAz-U7x"
      },
      "outputs": [],
      "source": [
        "g.edge_sets['bonds'].adjacency.source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwJM9FoKDXEr"
      },
      "outputs": [],
      "source": [
        "g.edge_sets['bonds'].adjacency.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI1X18IVC-5g"
      },
      "source": [
        "#### Edge features\n",
        "\n",
        "Edge features represent the bond type as one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_p-RgX6DS3F"
      },
      "outputs": [],
      "source": [
        "g.edge_sets['bonds'].features[tfgnn.HIDDEN_STATE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbeF1etYigfe"
      },
      "source": [
        "### Label\n",
        "The label is binary, indicating the mutagenicity of the molecule. It's either 0 or 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LgQGtPlwideV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lhmmug-DvyX"
      },
      "source": [
        "#### Batch the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOUCfdpp_w4v"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_ds_batched = train_ds.batch(batch_size=batch_size).repeat()\n",
        "val_ds_batched = val_ds.batch(batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Tqz_SPqyjY"
      },
      "source": [
        "### Build the GNN model\n",
        "\n",
        "TF-GNN provides Keras layers for building graph neural networks. The following code uses Keras' [Functional API](https://www.tensorflow.org/guide/keras/functional) to build a model as a series of GraphTensor transformations, followed by reading out a plain Tensor with the final prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7fhATRUexKh"
      },
      "outputs": [],
      "source": [
        "def _build_model(\n",
        "    graph_tensor_spec,\n",
        "    # Dimensions of initial states.\n",
        "    node_dim=16,\n",
        "    edge_dim=16,\n",
        "    # Dimensions for message passing.\n",
        "    message_dim=64,\n",
        "    next_state_dim=64,\n",
        "    # Dimension for the logits.\n",
        "    num_classes=2,\n",
        "    # Number of message passing steps.\n",
        "    num_message_passing=3,\n",
        "    # Other hyperparameters.\n",
        "    l2_regularization=5e-4,\n",
        "    dropout_rate=0.5,\n",
        "):\n",
        "  # Model building with Keras's Functional API starts with an input object\n",
        "  # (a placeholder for the eventual inputs). Here is how it works for\n",
        "  # GraphTensors:\n",
        "  input_graph = tf.keras.layers.Input(type_spec=graph_tensor_spec)\n",
        "\n",
        "  # IMPORTANT: All TF-GNN modeling code assumes a GraphTensor of shape []\n",
        "  # in which the graphs of the input batch have been merged to components of\n",
        "  # one contiguously indexed graph. (There are no edges between components,\n",
        "  # so no information flows between them.)\n",
        "  graph = input_graph.merge_batch_to_components()\n",
        "\n",
        "  # Nodes and edges have one-hot encoded input features. Sending them through\n",
        "  # a Dense layer effectively does a lookup in a trainable embedding table.\n",
        "  def set_initial_node_state(node_set, *, node_set_name):\n",
        "    # Since we only have one node set, we can ignore node_set_name.\n",
        "    return tf.keras.layers.Dense(node_dim)(node_set[tfgnn.HIDDEN_STATE])\n",
        "  def set_initial_edge_state(edge_set, *, edge_set_name):\n",
        "    return tf.keras.layers.Dense(edge_dim)(edge_set[tfgnn.HIDDEN_STATE])\n",
        "  graph = tfgnn.keras.layers.MapFeatures(\n",
        "      node_sets_fn=set_initial_node_state, edge_sets_fn=set_initial_edge_state)(\n",
        "          graph)\n",
        "\n",
        "  # This helper function is just a short-hand for the code below.\n",
        "  def dense(units, activation=\"relu\"):\n",
        "    \"\"\"A Dense layer with regularization (L2 and Dropout).\"\"\"\n",
        "    regularizer = tf.keras.regularizers.l2(l2_regularization)\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation=activation,\n",
        "            kernel_regularizer=regularizer,\n",
        "            bias_regularizer=regularizer),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "\n",
        "  # The GNN core of the model does `num_message_passing` many updates of node\n",
        "  # states conditioned on their neighbors and the edges connecting to them.\n",
        "  # More precisely:\n",
        "  #  - Each edge computes a message by applying a dense layer `message_fn`\n",
        "  #    to the concatenation of node states of both endpoints (by default)\n",
        "  #    and the edge's own unchanging feature embedding.\n",
        "  #  - Messages are summed up at the common TARGET nodes of edges.\n",
        "  #  - At each node, a dense layer is applied to the concatenation of the old\n",
        "  #    node state with the summed edge inputs to compute the new node state.\n",
        "  # Each iteration of the for-loop creates new Keras Layer objects, so each\n",
        "  # round of updates gets its own trainable variables.\n",
        "  for i in range(num_message_passing):\n",
        "    graph = tfgnn.keras.layers.GraphUpdate(\n",
        "        node_sets={\n",
        "            \"atoms\": tfgnn.keras.layers.NodeSetUpdate(\n",
        "                {\"bonds\": tfgnn.keras.layers.SimpleConv(\n",
        "                     sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
        "                     message_fn=dense(message_dim),\n",
        "                     reduce_type=\"sum\",\n",
        "                     receiver_tag=tfgnn.TARGET)},\n",
        "                tfgnn.keras.layers.NextStateFromConcat(dense(next_state_dim)))}\n",
        "    )(graph)\n",
        "\n",
        "  # After the GNN has computed a context-aware representation of the \"atoms\",\n",
        "  # the model reads out a representation for the graph as a whole by averaging\n",
        "  # (pooling) nde states into the graph context. The context is global to each\n",
        "  # input graph of the batch, so the first dimension of the result corresponds\n",
        "  # to the batch dimension of the inputs (same as the labels).\n",
        "  readout_features = tfgnn.keras.layers.Pool(\n",
        "      tfgnn.CONTEXT, \"mean\", node_set_name=\"atoms\")(graph)\n",
        "\n",
        "  # Put a linear classifier on top (not followed by dropout).\n",
        "  logits = tf.keras.layers.Dense(1)(readout_features)\n",
        "\n",
        "  # Build a Keras Model for the transformation from input_graph to logits.\n",
        "  return tf.keras.Model(inputs=[input_graph], outputs=[logits])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjM39AM2E0TD"
      },
      "source": [
        "#### Define Loss and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IAO1FToa5xk"
      },
      "outputs": [],
      "source": [
        "model_input_graph_spec, label_spec = train_ds.element_spec\n",
        "del label_spec # Unused.\n",
        "model = _build_model(model_input_graph_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcrTzMEfexIm"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = [tf.keras.metrics.BinaryAccuracy(threshold=0.),\n",
        "            tf.keras.metrics.BinaryCrossentropy(from_logits=True)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cREyDPxrFBH-"
      },
      "source": [
        "#### Compile the keras model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaSTzfbAexEj"
      },
      "outputs": [],
      "source": [
        "model.compile(tf.keras.optimizers.Adam(), loss=loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC4zLE2J8Hk_"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB5JoJ9pFDGx"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMotwUlM8U6s"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_ds_batched,\n",
        "                    steps_per_epoch=10,\n",
        "                    epochs=200,\n",
        "                    validation_data=val_ds_batched)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coXPPpmUFKAh"
      },
      "source": [
        "### Plot the loss and metric curves for train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qd2iuVZpsRH"
      },
      "outputs": [],
      "source": [
        "for k, hist in history.history.items():\n",
        "  plt.plot(hist)\n",
        "  plt.title(k)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGs6EyQz9jHM"
      },
      "source": [
        "Feel free to play with the hyperparameters and the model architecture to improve the results!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ScitaPqhKtuW"
      ],
      "name": "tfgnn-intro-mutag-example.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
